{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!pip install anthropic openai xai-sdk"
      ],
      "metadata": {
        "id": "l91jKpARTUhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Cross-Model Medical Triage Validation\n",
        "=====================================\n",
        "Evaluates ESI (Emergency Severity Index) classification accuracy across\n",
        "Claude Sonnet 4, GPT-5, and Grok-3 on 50 standardized emergency cases.\n",
        "\n",
        "Motivation: EU AI Act Article 15 requires continuous accuracy monitoring\n",
        "for high-risk AI systems. Medical triage represents a critical safety\n",
        "application requiring validated performance across model architectures.\n",
        "\n",
        "Contact: [your details]\n",
        "Date: September 2025\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "QcC_OFjhtHUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "__version__ = \"1.0.0\"\n",
        "__author__ = \"Javier Marín\"\n",
        "__license__ = \"MIT\"\n",
        "\n",
        "# Add versioning for reproducibility\n",
        "MODELS_TESTED = {\n",
        "    \"claude\": \"claude-sonnet-4-20250514\",\n",
        "    \"gpt\": \"gpt-5\",\n",
        "    \"grok\": \"grok-3\"\n",
        "}\n",
        "EXPERIMENT_DATE = \"2025-09-29\""
      ],
      "metadata": {
        "id": "ApWX0LumtIVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "import re\n",
        "from typing import Dict, List, Tuple\n",
        "import time\n",
        "import requests\n",
        "import nest_asyncio\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import chi2_contingency\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "from openai import OpenAI\n",
        "from xai_sdk import Client\n",
        "from xai_sdk.chat import user, system\n",
        "import anthropic\n"
      ],
      "metadata": {
        "id": "wouFurd1TbCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load test cases from JSON\n",
        "with open('test_cases.json', 'r') as f:\n",
        "    data = json.load(f)\n",
        "    ESI_TEST_CASES = data['test_cases']\n",
        "\n",
        "# Verify loading\n",
        "print(f\"Loaded {len(ESI_TEST_CASES)} cases\")\n",
        "print(f\"Stratification: {data['stratification']}\")"
      ],
      "metadata": {
        "id": "0O6S0Tyl0X4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiModelTriageExperiment:\n",
        "    \"\"\"\n",
        "    Cross-model validation of ESI-2 undertriage hypothesis.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, anthropic_key: str, openai_key: str, grok_key: str):\n",
        "        # Initialize clients\n",
        "        self.anthropic_client = anthropic.Anthropic(api_key=anthropic_key)\n",
        "        self.openai_client = OpenAI(api_key=openai_key)\n",
        "\n",
        "        # Grok uses OpenAI-compatible endpoint\n",
        "        self.grok_client = OpenAI(\n",
        "            api_key=grok_key,\n",
        "            base_url=\"https://api.x.ai/v1\"\n",
        "        )\n",
        "\n",
        "        self.results = []\n",
        "\n",
        "    def extract_urgency(self, response: str) -> str:\n",
        "        \"\"\"\n",
        "        Extract urgency classification from free-form model responses.\n",
        "        Handles multiple response formats robustly.\n",
        "        \"\"\"\n",
        "        text = response.strip()\n",
        "\n",
        "        # Primary patterns: explicit urgency declarations\n",
        "        patterns = [\n",
        "            r'\\*\\*Urgency(?:\\s+Level)?[:\\s]+([^\\*\\n]+)',\n",
        "            r'(?:^|\\n)\\s*Urgency(?:\\s+Level)?[:\\s]+([^\\n]+)',\n",
        "            r'\\*\\*([A-Z]+)\\*\\*\\s*[-–—]',\n",
        "        ]\n",
        "\n",
        "        for pattern in patterns:\n",
        "            match = re.search(pattern, text, re.IGNORECASE | re.MULTILINE)\n",
        "            if match:\n",
        "                extracted = match.group(1).strip().lower()\n",
        "                extracted = re.sub(r'[*\\-–—:]', '', extracted).strip()\n",
        "\n",
        "                if 'immediate' in extracted or 'emergency' in extracted:\n",
        "                    return 'immediate'\n",
        "                elif 'urgent' in extracted and 'immediate' not in extracted:\n",
        "                    return 'urgent'\n",
        "                elif 'routine' in extracted:\n",
        "                    return 'routine'\n",
        "\n",
        "        # Fallback: check first 200 characters\n",
        "        first_section = text[:200].lower()\n",
        "        if 'immediate' in first_section or 'life-threatening' in first_section:\n",
        "            return 'immediate'\n",
        "        elif 'urgent' in first_section:\n",
        "            return 'urgent'\n",
        "        elif 'routine' in first_section:\n",
        "            return 'routine'\n",
        "\n",
        "        return 'unknown'\n",
        "\n",
        "    def test_claude(self, query: str) -> Tuple[str, str]:\n",
        "        \"\"\"Test Claude Sonnet 4 using Messages API.\"\"\"\n",
        "        system_prompt = \"\"\"You are a medical triage expert using the Emergency Severity Index (ESI) framework.\n",
        "\n",
        "START your response with: **Urgency Level: [IMMEDIATE/URGENT/ROUTINE]**\n",
        "\n",
        "Then explain your reasoning. Use ESI criteria:\n",
        "- IMMEDIATE (ESI 1-2): Lifesaving intervention needed OR high-risk situation that could deteriorate\n",
        "- URGENT (ESI 3): Stable but needs multiple resources\n",
        "- ROUTINE (ESI 4-5): Minor issue, few/no resources needed\"\"\"\n",
        "\n",
        "        try:\n",
        "            message = self.anthropic_client.messages.create(\n",
        "                model=\"claude-sonnet-4-20250514\",\n",
        "                max_tokens=512,\n",
        "                system=system_prompt,\n",
        "                messages=[{\"role\": \"user\", \"content\": query}]\n",
        "            )\n",
        "            text = message.content[0].text\n",
        "            urgency = self.extract_urgency(text)\n",
        "            return urgency, text[:200]\n",
        "        except Exception as e:\n",
        "            print(f\"    [Claude Error: {str(e)[:80]}]\")\n",
        "            return 'error', str(e)[:200]\n",
        "\n",
        "    def test_gpt5(self, query: str) -> Tuple[str, str]:\n",
        "        \"\"\"Test GPT-5 using Responses API.\"\"\"\n",
        "        prompt = f\"\"\"You are a medical triage expert using the Emergency Severity Index (ESI) framework.\n",
        "\n",
        "START your response with: **Urgency Level: [IMMEDIATE/URGENT/ROUTINE]**\n",
        "\n",
        "Then explain your reasoning. Use ESI criteria:\n",
        "- IMMEDIATE (ESI 1-2): Lifesaving intervention needed OR high-risk situation that could deteriorate\n",
        "- URGENT (ESI 3): Stable but needs multiple resources\n",
        "- ROUTINE (ESI 4-5): Minor issue, few/no resources needed\n",
        "\n",
        "Patient presentation: {query}\"\"\"\n",
        "\n",
        "        try:\n",
        "            result = self.openai_client.responses.create(\n",
        "                model=\"gpt-5\",\n",
        "                input=prompt,\n",
        "                reasoning={\"effort\": \"low\"},\n",
        "                text={\"verbosity\": \"low\"}\n",
        "            )\n",
        "            text = result.output_text\n",
        "            urgency = self.extract_urgency(text)\n",
        "            return urgency, text[:200]\n",
        "        except Exception as e:\n",
        "            print(f\"    [GPT-5 Error: {str(e)[:80]}]\")\n",
        "            return 'error', str(e)[:200]\n",
        "\n",
        "    def test_grok(self, query: str) -> Tuple[str, str]:\n",
        "        \"\"\"Test Grok-3 using OpenAI-compatible endpoint.\"\"\"\n",
        "        system_prompt = \"\"\"You are a medical triage expert using the Emergency Severity Index (ESI) framework.\n",
        "\n",
        "START your response with: **Urgency Level: [IMMEDIATE/URGENT/ROUTINE]**\n",
        "\n",
        "Then explain your reasoning. Use ESI criteria:\n",
        "- IMMEDIATE (ESI 1-2): Lifesaving intervention needed OR high-risk situation that could deteriorate\n",
        "- URGENT (ESI 3): Stable but needs multiple resources\n",
        "- ROUTINE (ESI 4-5): Minor issue, few/no resources needed\"\"\"\n",
        "\n",
        "        try:\n",
        "            response = self.grok_client.chat.completions.create(\n",
        "                model=\"grok-3\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": system_prompt},\n",
        "                    {\"role\": \"user\", \"content\": query}\n",
        "                ],\n",
        "                temperature=0.7,\n",
        "                max_tokens=512\n",
        "            )\n",
        "            text = response.choices[0].message.content\n",
        "            urgency = self.extract_urgency(text)\n",
        "            return urgency, text[:200]\n",
        "        except Exception as e:\n",
        "            print(f\"    [Grok Error: {str(e)[:80]}]\")\n",
        "            return 'error', str(e)[:200]\n",
        "\n",
        "    def run_experiment(self):\n",
        "        \"\"\"Execute complete cross-model validation experiment.\"\"\"\n",
        "\n",
        "        for i, case in enumerate(ESI_TEST_CASES, 1):\n",
        "            print(f\"[{i:2d}/50] Case {case['case_id']:2d}: {case['category'][:28]:<28} ESI-{case['ground_truth_esi']}\", end=\" | \")\n",
        "\n",
        "            # Test all three models with rate limiting\n",
        "            claude_urgency, claude_resp = self.test_claude(case['query'])\n",
        "            time.sleep(0.5)\n",
        "\n",
        "            gpt_urgency, gpt_resp = self.test_gpt5(case['query'])\n",
        "            time.sleep(0.5)\n",
        "\n",
        "            grok_urgency, grok_resp = self.test_grok(case['query'])\n",
        "            time.sleep(0.5)\n",
        "\n",
        "            # Evaluate correctness\n",
        "            gt = case['ground_truth_urgency']\n",
        "            claude_correct = (claude_urgency == gt)\n",
        "            gpt_correct = (gpt_urgency == gt)\n",
        "            grok_correct = (grok_urgency == gt)\n",
        "\n",
        "            # Display results\n",
        "            print(f\"C:{claude_urgency[0].upper()}{'✓' if claude_correct else '✗'} \" +\n",
        "                  f\"G:{gpt_urgency[0].upper()}{'✓' if gpt_correct else '✗'} \" +\n",
        "                  f\"X:{grok_urgency[0].upper()}{'✓' if grok_correct else '✗'}\")\n",
        "\n",
        "            # Store complete results\n",
        "            self.results.append({\n",
        "                'case_id': case['case_id'],\n",
        "                'category': case['category'],\n",
        "                'ground_truth_esi': case['ground_truth_esi'],\n",
        "                'ground_truth_urgency': gt,\n",
        "                'claude_urgency': claude_urgency,\n",
        "                'gpt_urgency': gpt_urgency,\n",
        "                'grok_urgency': grok_urgency,\n",
        "                'claude_correct': claude_correct,\n",
        "                'gpt_correct': gpt_correct,\n",
        "                'grok_correct': grok_correct,\n",
        "                'query': case['query']\n",
        "            })\n",
        "\n",
        "        self.analyze_results()\n",
        "\n",
        "    def analyze_results(self):\n",
        "        \"\"\"Statistical analysis with proper handling of API failures.\"\"\"\n",
        "\n",
        "        df = pd.DataFrame(self.results)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*90)\n",
        "        print(\"STATISTICAL ANALYSIS\")\n",
        "        print(\"=\"*90)\n",
        "\n",
        "        # Filter out error responses for accuracy calculation\n",
        "        df_valid = df.copy()\n",
        "        for model in ['claude', 'gpt', 'grok']:\n",
        "            df_valid = df_valid[df_valid[f'{model}_urgency'] != 'error']\n",
        "            return\n",
        "\n",
        "        # Overall accuracy (only on valid responses)\n",
        "        print(f\"\\nOVERALL ACCURACY (n={len(df_valid)} valid responses):\")\n",
        "        for model in ['claude', 'gpt', 'grok']:\n",
        "            valid_model = df[df[f'{model}_urgency'] != 'error']\n",
        "            if len(valid_model) > 0:\n",
        "                acc = valid_model[f'{model}_correct'].mean()\n",
        "                n = len(valid_model)\n",
        "                print(f\"{model.capitalize():8s}: {acc:.1%} ({valid_model[f'{model}_correct'].sum()}/{n})\")\n",
        "            else:\n",
        "                print(f\"{model.capitalize():8s}: No valid responses\")\n",
        "\n",
        "        # ESI-2 specific analysis\n",
        "        print(\"\\nESI-2 UNDERTRIAGE ANALYSIS:\")\n",
        "        esi2_cases = df[df['ground_truth_esi'] == 2]\n",
        "\n",
        "        print(f\"\\nESI-2 Cases (n={len(esi2_cases)}):\")\n",
        "        for model in ['claude', 'gpt', 'grok']:\n",
        "            valid_esi2 = esi2_cases[esi2_cases[f'{model}_urgency'] != 'error']\n",
        "            if len(valid_esi2) > 0:\n",
        "                sens = valid_esi2[f'{model}_correct'].mean()\n",
        "                print(f\"{model.capitalize():8s} sensitivity: {sens:.1%} ({valid_esi2[f'{model}_correct'].sum()}/{len(valid_esi2)})\")\n",
        "            else:\n",
        "                print(f\"{model.capitalize():8s} sensitivity: No valid responses\")\n",
        "\n",
        "        # Inter-model agreement\n",
        "        working_models = [m for m in ['claude', 'gpt', 'grok']\n",
        "                         if (df[f'{m}_urgency'] != 'error').sum() > 10]\n",
        "\n",
        "        if len(working_models) >= 2:\n",
        "            print(\"\\nINTER-MODEL RELIABILITY (Cohen's Kappa):\")\n",
        "            for i, m1 in enumerate(working_models):\n",
        "                for m2 in working_models[i+1:]:\n",
        "                    valid_both = df[(df[f'{m1}_urgency'] != 'error') &\n",
        "                                   (df[f'{m2}_urgency'] != 'error')]\n",
        "                    if len(valid_both) > 10:\n",
        "                        kappa = cohen_kappa_score(valid_both[f'{m1}_correct'],\n",
        "                                                  valid_both[f'{m2}_correct'])\n",
        "                        print(f\"{m1.capitalize()}-{m2.capitalize()}: κ={kappa:.3f}\")\n",
        "\n",
        "        # Cases where all working models failed\n",
        "        if len(working_models) >= 2:\n",
        "            all_failed = df.copy()\n",
        "            for model in working_models:\n",
        "                all_failed = all_failed[~all_failed[f'{model}_correct'] &\n",
        "                                       (all_failed[f'{model}_urgency'] != 'error')]\n",
        "\n",
        "            if len(all_failed) > 0:\n",
        "                print(f\"\\nCASES WHERE ALL WORKING MODELS FAILED (n={len(all_failed)}):\")\n",
        "                for _, row in all_failed.head(5).iterrows():\n",
        "                    print(f\"  Case {row['case_id']}: {row['category']}\")\n",
        "                    print(f\"    Query: {row['query'][:70]}...\")\n",
        "\n",
        "        # Export\n",
        "        df.to_csv('cross_model_esi_validation.csv', index=False)"
      ],
      "metadata": {
        "id": "fJWyiEbqFrv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nest_asyncio.apply()\n",
        "# API Keys\n",
        "ANTHROPIC_KEY = \"\"\n",
        "OPENAI_KEY = \"\"\n",
        "GROK_KEY = \"\"\n",
        "\n",
        "# Initialize and run\n",
        "experiment = MultiModelTriageExperiment(\n",
        "    anthropic_key=ANTHROPIC_KEY,\n",
        "    openai_key=OPENAI_KEY,\n",
        "    grok_key=GROK_KEY\n",
        ")\n",
        "\n",
        "experiment.run_experiment()"
      ],
      "metadata": {
        "id": "iHsAa7-i8737"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}